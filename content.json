{"meta":{"title":"Dlog","subtitle":"All the past is a prelude","description":"All the past is a prelude，never Stop","author":"Zelong Zhang","url":"https://Dragon-GCS.github.io","root":"/"},"pages":[{"title":"关于","date":"2024-12-23T12:09:21.095Z","updated":"2024-12-23T12:09:21.095Z","comments":false,"path":"about/index.html","permalink":"https://dragon-gcs.github.io/about/","excerpt":"","text":"个人详细介绍"},{"title":"分类","date":"2024-12-23T12:09:21.095Z","updated":"2024-12-23T12:09:21.095Z","comments":false,"path":"categories/index.html","permalink":"https://dragon-gcs.github.io/categories/","excerpt":"","text":""},{"title":"Repositories","date":"2024-12-23T12:09:21.099Z","updated":"2024-12-23T12:09:21.099Z","comments":false,"path":"repository/index.html","permalink":"https://dragon-gcs.github.io/repository/","excerpt":"","text":""},{"title":"","date":"2024-12-23T12:09:21.096Z","updated":"2024-12-23T12:09:21.096Z","comments":true,"path":"css/GoL.css","permalink":"https://dragon-gcs.github.io/css/GoL.css","excerpt":"","text":"/* build time:Mon Mar 31 2025 18:38:40 GMT+0800 (中国标准时间)*/ @import url(https://fonts.googleapis.com/css2?family=Poppins:wght@300;400;500;600;700&display=swap);:root{--gol-dead:#fff;--gol-live:#000}#GoL{margin:0;padding:0 0;box-sizing:border-box;font-family:Poppins,sans-serif;background:var(--gol-dead);color:var(--gol-live);display:flex;flex-direction:column;align-items:center;justify-content:center;gap:.5rem}#GoL h1{margin:0;padding:0}#GoL .game{display:flex;align-items:center;padding:15px;border-radius:10px;box-shadow:inset 0 -3em 3em rgba(0,0,0,.1),0 0 0 2px #fff,.3em .3em 1em rgba(0,0,0,.3)}#GoL .game .control{display:flex;flex-direction:column;align-items:center;padding:0 20px}#GoL .game .control input{width:80px;height:30px;margin:10px;border-radius:10px}#GoL .game .control input[type=range]{margin-top:0}#GoL .game .control div{font-size:12px} /* rebuild by neat */"},{"title":"","date":"2024-12-23T12:09:21.096Z","updated":"2024-12-23T12:09:21.096Z","comments":true,"path":"js/GoL.js","permalink":"https://dragon-gcs.github.io/js/GoL.js","excerpt":"","text":"function drawLine(ctx, x1, y1, x2, y2) { ctx.beginPath(); ctx.moveTo(x1, y1); ctx.lineTo(x2, y2); ctx.stroke() } function drawBlock(ctx, x, y, color) { ctx.fillStyle = color; ctx.fillRect( x * BLOCK_WIDTH + 1, y * BLOCK_HEIGHT + 1, BLOCK_WIDTH - 2, BLOCK_HEIGHT - 2 ); } function initCanvas(ctx) { ctx.clearRect(0, 0, CANVAS_WIDTH, CANVAS_HEIGHT); ctx.fillStyle = DEAD_COLOR; ctx.fillRect(0, 0, CANVAS_WIDTH, CANVAS_HEIGHT); for (let i = 0; i < SIZE; i++) { drawLine(ctx, i * BLOCK_WIDTH, 0 , i * BLOCK_WIDTH, CANVAS_HEIGHT); } for (let j = 0; j < SIZE; j++) { drawLine(ctx, 0, j * BLOCK_HEIGHT, CANVAS_WIDTH, j * BLOCK_HEIGHT); } drawLine(ctx, CANVAS_WIDTH, 0, CANVAS_WIDTH, CANVAS_HEIGHT); drawLine(ctx, 0, CANVAS_HEIGHT, CANVAS_WIDTH, CANVAS_HEIGHT); } function initGame(ctx, clear = false) { initCanvas(ctx); let currentStatus = []; for (i = 0; i < SIZE; i++) { currentStatus.push([]); for (j = 0; j < SIZE; j++) { _status = 0 if (!clear && Math.random() < LIVE_BLOCK_RATE) { _status = 1; drawBlock(ctx, i, j, LIVE_COLOR); } currentStatus[i].push(_status); } } return currentStatus } function clickBlock(e) { let x = Math.floor(e.offsetX / BLOCK_WIDTH); let y = Math.floor(e.offsetY / BLOCK_HEIGHT); currentStatus[x][y] = 1 - currentStatus[x][y]; drawBlock(ctx, x, y, currentStatus[x][y] ? LIVE_COLOR : DEAD_COLOR); } function update(ctx) { if (!GAMING) { return; } let nextStatus = []; let changeFlag = 0 for (i = 0; i < SIZE; i++) { nextStatus.push([]); for (j = 0; j < SIZE; j++) { let liveCount = 0; for (k = -1; k { update(ctx) }, 1000 / FPS); }; document.getElementById(\"stop\").onclick = () => { GAMING = false; }; document.getElementById('restart').onclick = () => { GAMING = false currentStatus = initGame(ctx); }; document.getElementById('clear').onclick = () => { GAMING = false currentStatus = initGame(ctx, clear=true); };"},{"title":"404 Not Found：该页无法显示","date":"2024-12-23T12:09:20.968Z","updated":"2024-12-23T12:09:20.968Z","comments":false,"path":"/404.html","permalink":"https://dragon-gcs.github.io/404","excerpt":"","text":""},{"title":"友情链接","date":"2024-12-23T12:09:21.096Z","updated":"2024-12-23T12:09:21.096Z","comments":true,"path":"links/index.html","permalink":"https://dragon-gcs.github.io/links/","excerpt":"","text":""},{"title":"标签","date":"2024-12-23T12:09:21.099Z","updated":"2024-12-23T12:09:21.099Z","comments":false,"path":"tags/index.html","permalink":"https://dragon-gcs.github.io/tags/","excerpt":"","text":""}],"posts":[{"title":"深入解析Model Context Protocol(MCP)通信协议","slug":"MCP探究","date":"2025-03-31T06:18:20.000Z","updated":"2025-03-31T06:18:20.000Z","comments":true,"path":"2025/03-31-MCP探究.html","permalink":"https://dragon-gcs.github.io/2025/03-31-MCP%E6%8E%A2%E7%A9%B6","excerpt":"","text":"MCP（Model Context Protocol，模型上下文协议）是Anthropic在2024年推出的新型通信协议。该协议创新性地将工具调用能力从客户端解耦，使服务端能够通过标准化协议向客户端动态提供多种资源（包括工具、提示词模板、数据资源等）。 MCP与Function Call的技术对比在区分这两个概念之前，我们需要先了解一下大模型调用的流程（非流式调用）： 用户向大模型客户端（Claude，豆包等应用）提问 大模型客户端收到问题后进行审核，根据情况附带工具信息调用大模型API API厂商根据API输入对文本进行拼接，将拼接后的文本作为输入调用大模型 大模型输出文本 API厂商获取到模型的输出文本，解析后返回相应 大模型客户端拿到API响应后向客户输出答案 Function Call最初是OpenAI API中的一个参数，其本质是通过以下方式实现： 在API调用时传入工具定义（步骤2） 服务端将工具信息拼接到模型输入（步骤3） 模型按照指定格式输出调用信息 值得注意的是，任何具备良好指令遵循能力的大模型理论上都能实现类似功能。这也解释了为什么OpenAI的json mode能实现类似效果。 与Function Call相比，MCP具有以下显著特点： 特性 Function Call MCP 协议层级 API参数 独立协议 工具管理 客户端维护 服务端动态提供 通信方式 单次请求 持久化连接 扩展性 有限 强 MCP不是Function Call的替代品，而是提供了更完善的工具治理方案。虽然通过客户端内部调用可以模拟MCP功能，但会失去协议带来的标准化优势。 MCP的核心价值MCP解决了大模型生态中的关键痛点： 工具开发解耦 传统方式：客户端需集成所有工具，受限于开发语言 MCP方案：工具开发者只需遵循协议规范，与客户端完全解耦 动态能力发现 服务端可随时更新工具集 客户端自动获取最新能力 标准化协作 明确的服务边界 统一的通信规范 MCP协议通信详解我使用vscode的Roo Code插件作为MCP的客户端，连接到自己写的一个Demo服务上，以HTTP+SSE作为传输层，分析MCP的通信过程。 MCP服务端会开放两个APIPOST /messages/和GET /sse。客户端首先连接到/sse得到一个长连接和会话id，然后带着会话id向/messages/发送消息，服务端通过长连接返回相应。和基于stdio的传输做对比的话，/messages/就是输入流，/sse就是输出流 mcp_demo.py123456789101112131415logging.getLogger(&quot;mcp.server.sse&quot;).setLevel(logging.DEBUG)mcp = FastMCP(&quot;demo&quot;)@mcp.tool(name=&quot;Echo&quot;)def echo(text: str) -&gt; str: &quot;&quot;&quot;Echo the input text.&quot;&quot;&quot; return text@mcp.resource(&quot;file://&#123;filename&#125;&quot;)def read_file(filename: str) -&gt; str: &quot;&quot;&quot;Read the content of a file.&quot;&quot;&quot; return f&quot;&#123;filename&#125; content&quot;if __name__ == &#x27;__main__&#x27;: mcp.run(transport=&quot;sse&quot;) 为了看到服务端发送的消息，我调整了mcp的日志级别，同时在sse-starlette源码中添加了输出，以便看到最原始的响应内容。 sse_starlette/sse.py# EventSourceResponse._stream_response:156async for data in self.body_iterator: chunk = ensure_bytes(data, self.sep) print(repr(chunk)) 通过输出日志，我们可以清晰看到完整的握手过程与MCP的协议内容一致： Line5: 客户端发送请求 Line8: 服务端返回响应，其中携带session_id，客户端服务端连接建立 Line12: 客户端发送版本信息initialize request Line24: 服务端返回版本信息initialize response Line27: 客户端发送initialized notification，握手完成 Line35: 客户端发送tools/list请求 Line43: 服务端返回可用的工具列表 Line46: 客户端发送resources/list请求 Line52: 服务端返回可用的资源列表 Line55: 客户端发送resources/templates/list请求 Line64: 服务端返回可用的资源模版列表 Line65: 心跳信息 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566[03/31/25 16:07:10] DEBUG Setting up SSE connection sse.py:87 DEBUG Created new session with ID: b0ef1e12-33bc-42dc-ad70-4bbb53e8940e sse.py:100 DEBUG Starting SSE response task sse.py:127 DEBUG Yielding read and write streams sse.py:130INFO: 127.0.0.1:64046 - &quot;GET /sse HTTP/1.1&quot; 200 OK DEBUG Starting SSE writer sse.py:107 DEBUG Sent endpoint event: /messages/?session_id=b0ef1e1233bc42dcad704bbb53e8940e sse.py:110&#x27;event: endpoint\\r\\ndata: /messages/?session_id=b0ef1e1233bc42dcad704bbb53e8940e\\r\\n\\r\\n&#x27; DEBUG Handling POST message sse.py:136 DEBUG Parsed session ID: b0ef1e12-33bc-42dc-ad70-4bbb53e8940e sse.py:147 DEBUG Received JSON: sse.py:160 b&#x27;&#123;&quot;method&quot;:&quot;initialize&quot;,&quot;params&quot;:&#123;&quot;protocolVersion&quot;:&quot;2024-11-05&quot;,&quot;capabilities&quot;:&#123;&#125;,&quot;clientInfo&quot;:&#123;&quot;name&quot;:&quot;R oo Code&quot;,&quot;version&quot;:&quot;3.11.1&quot;&#125;&#125;,&quot;jsonrpc&quot;:&quot;2.0&quot;,&quot;id&quot;:0&#125;&#x27; DEBUG Validated client message: root=JSONRPCRequest(method=&#x27;initialize&#x27;, params=&#123;&#x27;protocolVersion&#x27;: &#x27;2024-11-05&#x27;, sse.py:164 &#x27;capabilities&#x27;: &#123;&#125;, &#x27;clientInfo&#x27;: &#123;&#x27;name&#x27;: &#x27;Roo Code&#x27;, &#x27;version&#x27;: &#x27;3.11.1&#x27;&#125;&#125;, jsonrpc=&#x27;2.0&#x27;, id=0) DEBUG Sending message to writer: root=JSONRPCRequest(method=&#x27;initialize&#x27;, params=&#123;&#x27;protocolVersion&#x27;: sse.py:172 &#x27;2024-11-05&#x27;, &#x27;capabilities&#x27;: &#123;&#125;, &#x27;clientInfo&#x27;: &#123;&#x27;name&#x27;: &#x27;Roo Code&#x27;, &#x27;version&#x27;: &#x27;3.11.1&#x27;&#125;&#125;, jsonrpc=&#x27;2.0&#x27;, id=0) INFO: 127.0.0.1:64047 - &quot;POST /messages/?session_id=b0ef1e1233bc42dcad704bbb53e8940e HTTP/1.1&quot; 202 Accepted DEBUG Sending message via SSE: root=JSONRPCResponse(jsonrpc=&#x27;2.0&#x27;, id=0, result=&#123;&#x27;protocolVersion&#x27;: &#x27;2024-11-05&#x27;, sse.py:113 &#x27;capabilities&#x27;: &#123;&#x27;experimental&#x27;: &#123;&#125;, &#x27;prompts&#x27;: &#123;&#x27;listChanged&#x27;: False&#125;, &#x27;resources&#x27;: &#123;&#x27;subscribe&#x27;: False, &#x27;listChanged&#x27;: False&#125;, &#x27;tools&#x27;: &#123;&#x27;listChanged&#x27;: False&#125;&#125;, &#x27;serverInfo&#x27;: &#123;&#x27;name&#x27;: &#x27;demo&#x27;, &#x27;version&#x27;: &#x27;1.6.0&#x27;&#125;&#125;) &#x27;event: message\\r\\ndata: &#123;&quot;jsonrpc&quot;:&quot;2.0&quot;,&quot;id&quot;:0,&quot;result&quot;:&#123;&quot;protocolVersion&quot;:&quot;2024-11-05&quot;,&quot;capabilities&quot;:&#123;&quot;experimental&quot;:&#123;&#125;,&quot;prompts&quot;:&#123;&quot;listChanged&quot;:false&#125;,&quot;resources&quot;:&#123;&quot;subscribe&quot;:false,&quot;listChanged&quot;:false&#125;,&quot;tools&quot;:&#123;&quot;listChanged&quot;:false&#125;&#125;,&quot;serverInfo&quot;:&#123;&quot;name&quot;:&quot;demo&quot;,&quot;version&quot;:&quot;1.6.0&quot;&#125;&#125;&#125;\\r\\n\\r\\n&#x27; DEBUG Handling POST message sse.py:136 DEBUG Parsed session ID: b0ef1e12-33bc-42dc-ad70-4bbb53e8940e sse.py:147 DEBUG Received JSON: b&#x27;&#123;&quot;method&quot;:&quot;notifications/initialized&quot;,&quot;jsonrpc&quot;:&quot;2.0&quot;&#125;&#x27; sse.py:160 DEBUG Validated client message: root=JSONRPCNotification(method=&#x27;notifications/initialized&#x27;, params=None, sse.py:164 jsonrpc=&#x27;2.0&#x27;) DEBUG Sending message to writer: root=JSONRPCNotification(method=&#x27;notifications/initialized&#x27;, params=None, sse.py:172 jsonrpc=&#x27;2.0&#x27;) INFO: 127.0.0.1:64048 - &quot;POST /messages/?session_id=b0ef1e1233bc42dcad704bbb53e8940e HTTP/1.1&quot; 202 Accepted DEBUG Handling POST message sse.py:136 DEBUG Parsed session ID: b0ef1e12-33bc-42dc-ad70-4bbb53e8940e sse.py:147 DEBUG Received JSON: b&#x27;&#123;&quot;method&quot;:&quot;tools/list&quot;,&quot;jsonrpc&quot;:&quot;2.0&quot;,&quot;id&quot;:1&#125;&#x27; sse.py:160 DEBUG Validated client message: root=JSONRPCRequest(method=&#x27;tools/list&#x27;, params=None, jsonrpc=&#x27;2.0&#x27;, id=1) sse.py:164 DEBUG Sending message to writer: root=JSONRPCRequest(method=&#x27;tools/list&#x27;, params=None, jsonrpc=&#x27;2.0&#x27;, id=1) sse.py:172INFO: 127.0.0.1:64049 - &quot;POST /messages/?session_id=b0ef1e1233bc42dcad704bbb53e8940e HTTP/1.1&quot; 202 Accepted INFO Processing request of type ListToolsRequest server.py:534 DEBUG Sending message via SSE: root=JSONRPCResponse(jsonrpc=&#x27;2.0&#x27;, id=1, result=&#123;&#x27;tools&#x27;: [&#123;&#x27;name&#x27;: &#x27;Echo&#x27;, sse.py:113 &#x27;description&#x27;: &#x27;Echo the input text.&#x27;, &#x27;inputSchema&#x27;: &#123;&#x27;properties&#x27;: &#123;&#x27;text&#x27;: &#123;&#x27;title&#x27;: &#x27;Text&#x27;, &#x27;type&#x27;: &#x27;string&#x27;&#125;&#125;, &#x27;required&#x27;: [&#x27;text&#x27;], &#x27;title&#x27;: &#x27;echoArguments&#x27;, &#x27;type&#x27;: &#x27;object&#x27;&#125;&#125;]&#125;) &#x27;event: message\\r\\ndata: &#123;&quot;jsonrpc&quot;:&quot;2.0&quot;,&quot;id&quot;:1,&quot;result&quot;:&#123;&quot;tools&quot;:[&#123;&quot;name&quot;:&quot;Echo&quot;,&quot;description&quot;:&quot;Echo the input text.&quot;,&quot;inputSchema&quot;:&#123;&quot;properties&quot;:&#123;&quot;text&quot;:&#123;&quot;title&quot;:&quot;Text&quot;,&quot;type&quot;:&quot;string&quot;&#125;&#125;,&quot;required&quot;:[&quot;text&quot;],&quot;title&quot;:&quot;echoArguments&quot;,&quot;type&quot;:&quot;object&quot;&#125;&#125;]&#125;&#125;\\r\\n\\r\\n&#x27; DEBUG Handling POST message sse.py:136 DEBUG Parsed session ID: b0ef1e12-33bc-42dc-ad70-4bbb53e8940e sse.py:147 DEBUG Received JSON: b&#x27;&#123;&quot;method&quot;:&quot;resources/list&quot;,&quot;jsonrpc&quot;:&quot;2.0&quot;,&quot;id&quot;:2&#125;&#x27; sse.py:160 DEBUG Validated client message: root=JSONRPCRequest(method=&#x27;resources/list&#x27;, params=None, jsonrpc=&#x27;2.0&#x27;, id=2) sse.py:164 DEBUG Sending message to writer: root=JSONRPCRequest(method=&#x27;resources/list&#x27;, params=None, jsonrpc=&#x27;2.0&#x27;, id=2) sse.py:172INFO: 127.0.0.1:64050 - &quot;POST /messages/?session_id=b0ef1e1233bc42dcad704bbb53e8940e HTTP/1.1&quot; 202 Accepted INFO Processing request of type ListResourcesRequest server.py:534 DEBUG Sending message via SSE: root=JSONRPCResponse(jsonrpc=&#x27;2.0&#x27;, id=2, result=&#123;&#x27;resources&#x27;: []&#125;) sse.py:113&#x27;event: message\\r\\ndata: &#123;&quot;jsonrpc&quot;:&quot;2.0&quot;,&quot;id&quot;:2,&quot;result&quot;:&#123;&quot;resources&quot;:[]&#125;&#125;\\r\\n\\r\\n&#x27; DEBUG Handling POST message sse.py:136 DEBUG Parsed session ID: b0ef1e12-33bc-42dc-ad70-4bbb53e8940e sse.py:147 DEBUG Received JSON: b&#x27;&#123;&quot;method&quot;:&quot;resources/templates/list&quot;,&quot;jsonrpc&quot;:&quot;2.0&quot;,&quot;id&quot;:3&#125;&#x27; sse.py:160 DEBUG Validated client message: root=JSONRPCRequest(method=&#x27;resources/templates/list&#x27;, params=None, sse.py:164 jsonrpc=&#x27;2.0&#x27;, id=3) DEBUG Sending message to writer: root=JSONRPCRequest(method=&#x27;resources/templates/list&#x27;, params=None, sse.py:172 jsonrpc=&#x27;2.0&#x27;, id=3) INFO: 127.0.0.1:64051 - &quot;POST /messages/?session_id=b0ef1e1233bc42dcad704bbb53e8940e HTTP/1.1&quot; 202 Accepted INFO Processing request of type ListResourceTemplatesRequest server.py:534 DEBUG Sending message via SSE: root=JSONRPCResponse(jsonrpc=&#x27;2.0&#x27;, id=3, result=&#123;&#x27;resourceTemplates&#x27;: sse.py:113 [&#123;&#x27;uriTemplate&#x27;: &#x27;file://&#123;filename&#125;&#x27;, &#x27;name&#x27;: &#x27;read_file&#x27;, &#x27;description&#x27;: &#x27;Read the content of a file.&#x27;&#125;]&#125;) &#x27;event: message\\r\\ndata: &#123;&quot;jsonrpc&quot;:&quot;2.0&quot;,&quot;id&quot;:3,&quot;result&quot;:&#123;&quot;resourceTemplates&quot;:[&#123;&quot;uriTemplate&quot;:&quot;file://&#123;filename&#125;&quot;,&quot;name&quot;:&quot;read_file&quot;,&quot;description&quot;:&quot;Read the content of a file.&quot;&#125;]&#125;&#125;\\r\\n\\r\\n&#x27;&#x27;: ping - 2025-03-31 08:07:25.512781+00:00\\r\\n\\r\\n&#x27;&#x27;: ping - 2025-03-31 08:07:40.513592+00:00\\r\\n\\r\\n&#x27; MCP的Token开销由于MCP需要在对话中嵌入工具描述，必然会产生额外的Token消耗。关键影响因素包括： 工具描述的详细程度 工具数量 Prompt拼接方式 实际Prompt拼接内容样例可参考技术爬爬虾的视频MCP是怎么对接大模型的？抓取AI提示词，拆解MCP的底层原理。 注意：不同客户端的调用工具的实现并不一致 总结MCP协议为大模型应用开发带来了三大革新： 工程化：规范化的工具开发流程 生态化：跨平台的能力共享 专业化：明确的责任分工 随着AI工程化的发展，MCP这类标准化协议将发挥越来越重要的作用。","categories":[{"name":"技术探索","slug":"技术探索","permalink":"https://dragon-gcs.github.io/categories/%E6%8A%80%E6%9C%AF%E6%8E%A2%E7%B4%A2/"}],"tags":[{"name":"AI","slug":"AI","permalink":"https://dragon-gcs.github.io/tags/AI/"}]},{"title":"Unraid部署HomeAssistant+米家+HomeKit集成","slug":"Unraid部署HomeAssistant-米家-HomeKit集成","date":"2024-12-23T13:10:09.000Z","updated":"2024-12-23T13:10:09.000Z","comments":true,"path":"2024/12-23-Unraid部署HomeAssistant-米家-HomeKit集成.html","permalink":"https://dragon-gcs.github.io/2024/12-23-Unraid%E9%83%A8%E7%BD%B2HomeAssistant-%E7%B1%B3%E5%AE%B6-HomeKit%E9%9B%86%E6%88%90","excerpt":"","text":"","categories":[{"name":"NAS","slug":"NAS","permalink":"https://dragon-gcs.github.io/categories/NAS/"}],"tags":[{"name":"HomeAssistant","slug":"HomeAssistant","permalink":"https://dragon-gcs.github.io/tags/HomeAssistant/"}]},{"title":"eu.org免费域名注册","slug":"eu.org免费域名注册","date":"2024-06-29T02:32:24.000Z","updated":"2024-06-29T02:32:24.000Z","comments":true,"path":"2024/06-29-eu.org免费域名注册.html","permalink":"https://dragon-gcs.github.io/2024/06-29-eu.org%E5%85%8D%E8%B4%B9%E5%9F%9F%E5%90%8D%E6%B3%A8%E5%86%8C","excerpt":"","text":"eu.org是一个免费的域名提供商，可以申请以.eu.org结尾的域名，注册过程比较简单，但是审核时间较长，需要耐心等待。注册完成后可以使用cloudflare或dnspod等dns服务商提供的免费dns服务，实现域名解析。 register.us.kg 也可以提供免费域名，流程和eu.org类似，但是注册后的域名是以.us.kg结尾的。 优点：不需要漫长的等待时间。eu.org半年也不一定能审核通过。 缺点：即使开了代理，访问网站也会不稳定，比较看运行。 注册账号域名注册地址: https://nic.eu.org/, 首页长下边这样, 网站建于1996年，没有太多钱维护，还是上世纪的UI。 点击here进入下边的注册页面。 红框部分不需要填，只需要填写以下部分即可 姓名，可能名字中间要有空格才能通过 邮箱，用于接收验证邮件 地址，从小到大填三个就可以 国家，试了下填中国不影响注册 密码 注册后会收到一封验证邮件，点击验证链接即可。 DNS服务申请网上有很多详细的教程，这里只是简单描述下。注册一个cloudflare账号，登录后点击添加站点。 第一步输入你准备申请的域名，检查通过后进入下一步 第二步确认计划选择最下边的免费计划 第三步扫描该域名当前的dns，如果你的域名没人注册，那扫描结果应该为空 第四步激活，这里会显示两个名称服务器，复制下来，后续会用到 最后一步要等域名申请下来才能彻底完成 注册域名注册完成后会生成一个 -Free 结尾的账号，用该账号登录后，点击New domain进入域名申请页面。 第一个红框要填你需要注册域名全称：example.eu.org，结尾除了.eu.org也可以使用一些带有国名的后缀，如.fr.eu.org。详细列表可以在这里查看。 最后的Name servers是用来验证域名的dns服务器，可以用cloudflare或dnspod提供的免费dns服务，我这里使用的是刚才在cloudflare上获取的两个名称服务器。 填写完成后点击提交，没问题的会在新页面里最后几行里显示一个request-id，表示申请已经提交，等待后续审核通过即可。","categories":[{"name":"Website","slug":"Website","permalink":"https://dragon-gcs.github.io/categories/Website/"}],"tags":[{"name":"dns","slug":"dns","permalink":"https://dragon-gcs.github.io/tags/dns/"},{"name":"cloudflare","slug":"cloudflare","permalink":"https://dragon-gcs.github.io/tags/cloudflare/"},{"name":"domain","slug":"domain","permalink":"https://dragon-gcs.github.io/tags/domain/"}]},{"title":"Rust相关资料","slug":"Rust相关资料","date":"2024-06-14T00:12:21.000Z","updated":"2024-06-14T00:12:21.000Z","comments":true,"path":"2024/06-14-Rust相关资料.html","permalink":"https://dragon-gcs.github.io/2024/06-14-Rust%E7%9B%B8%E5%85%B3%E8%B5%84%E6%96%99","excerpt":"","text":"Rust学习过程中一些资料的整理 Serde属性大全: Rust序列化、反序列化方案：Serde Rust中Result,Option的使用: Result官方文档 Option官方文档","categories":[{"name":"Learning","slug":"Learning","permalink":"https://dragon-gcs.github.io/categories/Learning/"}],"tags":[{"name":"Rust","slug":"Rust","permalink":"https://dragon-gcs.github.io/tags/Rust/"}]},{"title":"万物皆可Rss","slug":"万物皆可Rss","date":"2024-03-05T12:34:56.000Z","updated":"2024-03-05T12:34:56.000Z","comments":true,"path":"2024/03-05-万物皆可Rss.html","permalink":"https://dragon-gcs.github.io/2024/03-05-%E4%B8%87%E7%89%A9%E7%9A%86%E5%8F%AFRss","excerpt":"","text":"介绍一个关于RSS的项目DIYgod&#x2F;RSSHub 项目的宗旨就是文章的标题 – 万物皆可RSS。 该项目依赖爬虫技术将页面解析为RSS所需的订阅格式，然后通过路由的方式提供订阅服务。项目的拓展性极强，任何人都可以通过提交PR的方式添加新的页面解析和路由。 (制作自己的 RSSHub 路由) 部署自己的订阅服务器RssHub官方提供了一个订阅源服务器https://rsshub.app，同时它也支持用户自己部署订阅源服务器，具体可以参考部署文档 以下是我在Azure云上通过docker部署的过程记录。 拉取最新的RssHub镜像，并启动容器，将容器内的1200端口映射到主机的9200端口。 #!/bin/bash# rsshub-docker.shdocker run -d --name rsshub -p 9200:1200 diygod/rsshub 修改Nginx配置文件，将域名反向代理至Rsshub端口 123456789101112131415# /etc/nginx/sites-enabled/defaultserver &#123; server_name rss.myhost.com; listen 80; listen 443 ; ssl_certificate /etc/letsencrypt/live/myhost.com/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/myhost.com/privkey.pem; location / &#123; proxy_pass http://localhost:9200; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125;&#125; 配置nginx踩坑由于之前有一个域名已经使用了ssl并监听了443端口，因此一开始写的是listen 443 ssl，但是这样会导致nginx启动失败，提示监听了重复的端口。经过一番查找后发现只要去掉ssl，写为listen 443即可。 原因貌似是因为第一个写的是default_server，因此后边不用针对ssl再次配置。 重启Nginxnginx -s reload，将官方订阅的rsshub.app替换为我自己的域名rss.myhost.com即可。 自建服务器相比于官方服务有两个好处 自己的服务器不在国内，可以免代理使用一些国外的订阅源 一部分订阅源需要使用cookie，因此只能使用自己的服务器 一些订阅源推荐更多订阅源请参考官方文档 知乎热榜： https://rsshub.app/zhihu/hotlist 知乎日报： https://rsshub.app/zhihu/daily 哔哩哔哩热门： https://rsshub.app/bilibili/popular/all HackerNew： https://rsshub.app/hackernews HelloGithub： https://rsshub.app/hellogithub/volumn GithubTrending: https://rsshub.app/github/trending/weekly/any","categories":[{"name":"FunnyCoding","slug":"FunnyCoding","permalink":"https://dragon-gcs.github.io/categories/FunnyCoding/"}],"tags":[{"name":"工具分享","slug":"工具分享","permalink":"https://dragon-gcs.github.io/tags/%E5%B7%A5%E5%85%B7%E5%88%86%E4%BA%AB/"}]},{"title":"从Uvicorn到fastapi处理请求之间发生了什么？","slug":"从uvicorn到fastapi处理请求之间发生了什么？","date":"2023-09-27T13:07:20.000Z","updated":"2023-09-27T13:07:20.000Z","comments":true,"path":"2023/09-27-从uvicorn到fastapi处理请求之间发生了什么？.html","permalink":"https://dragon-gcs.github.io/2023/09-27-%E4%BB%8Euvicorn%E5%88%B0fastapi%E5%A4%84%E7%90%86%E8%AF%B7%E6%B1%82%E4%B9%8B%E9%97%B4%E5%8F%91%E7%94%9F%E4%BA%86%E4%BB%80%E4%B9%88%EF%BC%9F","excerpt":"","text":"十一放假，在家学习 FastAPI是一个基于seattle的异步web框架， 据说其速度和go语言相当。uvicorn&#x2F;Gunicorn是一个基于asyncio的异步服务器，用于启动fastapi，其中Gunicorn多进程启动时有负载均衡的功能。 本次源码阅读主要是为了解决我内心的一些疑惑： uvicorn启动之后，如何将端口请求传递给fastapi？ fastapi拿到请求后如何调用的endpoint函数？ endpoint处理完成后如何返回请求？ fastapi的endpoint如果做到同时适配同步函数和异步函数的？ 源码版本fastapi &#x3D;&#x3D; 0.103.1uvicorn &#x3D;&#x3D; 0.23.2 1. 从uvicorn到fastapi1.1 启动uvicorn.run(&quot;server:app&quot;)1234567891011121314# uvicorn/main.pydef run(...): config = Config(...) server = Server(config=config) ... if config.should_reload: sock = config.bind_socket() ChangeReload(config, target=server.run, sockets=[sock]).run() elif config.workers &gt; 1: sock = config.bind_socket() Multiprocess(config, target=server.run, sockets=[sock]).run() else: server.run() ... uvicorn启动后将run的参数全部传给了Config，实例化之后又传递给了server对象。之后主要运行的就是server.run()函数。 可以看到在启用reload或works之后会创建一个目标端口的套接字，这个主要是为了在多个进程间共享同一个socket对象。 12345678910111213141516171819202122# uvicorn/server.pydef run(self, sockets: Optional[List[socket.socket]] = None) -&gt; None: ... return asyncio.run(self.serve(sockets=sockets))async def serve(self, sockets: Optional[List[socket.socket]] = None) -&gt; None: ... await self.startup(sockets=sockets) if self.should_exit: return await self.main_loop() await self.shutdown(sockets=sockets) ...async def main_loop(self) -&gt; None: counter = 0 should_exit = await self.on_tick(counter) while not should_exit: counter += 1 counter = counter % 864000 await asyncio.sleep(0.1) should_exit = await self.on_tick(counter) 代码中可以看到server.run()调用了server.serve()函数，而server.serve()中主要做的就是startup(),main_loop()以及当self.show_exit=True之后运行的shutdown()函数。 main_loop主要的作用就是保持代码的运行。所以关键代码应该在startup()中 1.2 启动端口监听loop.create_server()和ASGI协议123456789101112131415161718192021222324252627282930# uvicorn/server.pyasync def startup(self, sockets: Optional[List[socket.socket]] = None) -&gt; None: ... def create_protocol( _loop: Optional[asyncio.AbstractEventLoop] = None, ) -&gt; asyncio.Protocol: return config.http_protocol_class(...) ... if sockets is not None: ... elif ... else: try: server = await loop.create_server( create_protocol, host=config.host, port=config.port, ... ) except OSError as exc: ...# config.http_protocol_class的初始化在Config.load()函数中# uvicorn/config.pydef load(self): ... if isinstance(self.http, str): http_protocol_class = import_from_string(HTTP_PROTOCOLS[self.http]) self.http_protocol_class: Type[asyncio.Protocol] = http_protocol_class else: self.http_protocol_class = self.http uvicorn通过asyncio的底层接loop.create_server()启动了一个监听指定端口的server，fastapi的应用程序就运行在这个server中。config.http_protocol_class()是一个实现了python异步基础协议的类，这里默认是uvicron.protocols.http.h11_impl.H11Protocol。协议规定了需要实现data_data_received(data)用于处理接收到的数据 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354# uvicorn/protocols/http/h11_impl.pydef data_received(self, data: bytes) -&gt; None: ... self.handle_events()def handle_events(self) -&gt; None: while True: try: event = self.conn.next_event() except h11.RemoteProtocolError: ... if event is h11.NEED_DATA: ... elif ... elif isinstance(event, h11.Request): ... self.headers = [(key.lower(), value) for key, value in event.headers] raw_path, _, query_string = event.target.partition(b&quot;?&quot;) self.scope = &#123; &quot;type&quot;: &quot;http&quot;, &quot;asgi&quot;: &#123; &quot;version&quot;: self.config.asgi_version, &quot;spec_version&quot;: &quot;2.3&quot;, &#125;, &quot;http_version&quot;: event.http_version.decode(&quot;ascii&quot;), &quot;server&quot;: self.server, &quot;client&quot;: self.client, &quot;scheme&quot;: self.scheme, &quot;method&quot;: event.method.decode(&quot;ascii&quot;), &quot;root_path&quot;: self.root_path, &quot;path&quot;: unquote(raw_path.decode(&quot;ascii&quot;)), &quot;raw_path&quot;: raw_path, &quot;query_string&quot;: query_string, &quot;headers&quot;: self.headers, &quot;state&quot;: self.app_state.copy(), &#125; upgrade = self._get_upgrade() if upgrade == b&quot;websocket&quot; and self._should_upgrade_to_ws(): self.handle_websocket_upgrade(event) return # Handle 503 responses when &#x27;limit_concurrency&#x27; is exceeded. if ... else: app = self.app self.cycle = RequestResponseCycle( scope=self.scope, ... ) task = self.loop.create_task(self.cycle.run_asgi(app)) task.add_done_callback(self.tasks.discard) self.tasks.add(task) ... 这里可以看到uvicorn中解析了请求的路径、参数、请求头等并保存到了scope中，随后实例化了RequestResponseCycle并异步调用了run_asgi()方法 async def run_asgi(self, app: &quot;ASGI3Application&quot;) -&gt; None: try: result = await app(self.scope, self.receive, self.send) except ... 这一行 result = await app(self.scope, self.receive, self.send)就是ASGI协议的主要内容。ASGI规定了app需要实现app(data, receive, send)，从而使服务端能够与app进行通讯。 至此，我们就理解了uvicorn是如何将收到的请求传递给FastAPI的了: uvicorn通过asyncio底层接口启动一个监听端口的server server收到请求后解析请求头、请求路径等信息后保存在scope中 通过ASGI协议调用FastAPI app，完成信息传递 2. FastAPI调用endpointapp通过app(data, receive, send)方法来处理uvicorn传递的数据，由于fastapi的app是一个对象而非函数，所以我们从app的__call__()方法作为入口开始分析。 # fastapi/application.pyasync def __call__(self, scope: Scope, receive: Receive, send: Send) -&gt; None: ... await super().__call__(scope, receive, send) FastAPI直接继承了starlette.Starlette()，所以我们继续去看starlette的代码 123456789101112131415# starlette.application.pyasync def __call__(self, scope: Scope, receive: Receive, send: Send) -&gt; None: scope[&quot;app&quot;] = self if self.middleware_stack is None: self.middleware_stack = self.build_middleware_stack() await self.middleware_stack(scope, receive, send)def build_middleware_stack(self) -&gt; ASGIApp: ... middleware = [Middleware(...), ...] app = self.router for cls, options in reversed(middleware): app = cls(app=app, **options) return app starlette创建了多个中间件，并一层层额的调用，最内层为self.router。所以app(scope, receive, send)最终的调用是self.router(scope, receive, send)。FastAPI中router是自己定义的APIRouter，我们这里需要回到fastapi看它是如何实现这部分的。 1234567891011121314151617181920# fastapi/routing.pyclass APIRouter(routing.Router):# starlette/routing.pyclass Router: async def __call__(self, scope: Scope, receive: Receive, send: Send) -&gt; None: assert scope[&quot;type&quot;] in (&quot;http&quot;, &quot;websocket&quot;, &quot;lifespan&quot;) ... partial = None for route in self.routes: match, child_scope = route.matches(scope) if match == Match.FULL: scope.update(child_scope) await route.handle(scope, receive, send) return elif match == Match.PARTIAL and partial is None: partial = route partial_scope = child_scope if partial is not None: ... 当调用router(scope, receive, send)时，他会遍历所有注册的路由去寻找匹配的route来对传入的数据进行处理。我们继续看FastAPI默认使用的APIRoute.handle(scope, receive, send)是如何工作的。 # fastapi/routingg.pyclass APIRoute(routing.Route): # 没有重载handle方法# starlette/routing.pyclass Route: async def handle(self, scope: Scope, receive: Receive, send: Send) -&gt; None: if self.methods and scope[&quot;method&quot;] not in self.methods: ... else: await self.app(scope, receive, send) FastAPI中的APIRoute继承自starlette.routing.Route。其中handle()方法的主要内容就是调用了自己的app(scope, receive, send)方法，而FastAPI中对route的app属性做了修改，所以我们继续看FastAPI的代码。 1234567891011121314151617181920212223242526272829303132333435363738# fastapi/routing.pyclass APIRoute(routing.Route): def __init__(self, path, endpoint, ...) -&gt; None: ... self.endpoint = endpoint ... # 这里将endpoint保存到了dependant.call属性中 self.dependant = get_dependant(path=self.path_format, call=self.endpoint) ... # 这里是关健 self.app = request_response(self.get_route_handler()) def get_route_handler(self): return get_request_handler(dependant=self.dependant, ...)def get_request_handler(dependant): is_coroutine = asyncio.iscoroutinefunction(dependant.call) async def app(request: Request) -&gt; Response: if ... else: raw_response = await run_endpoint_function( dependant=dependant, values=values, is_coroutine=is_coroutine ) return response return app# starlette/routing.pydef request_response(func: typing.Callable) -&gt; ASGIApp: is_coroutine = is_async_callable(func) async def app(scope: Scope, receive: Receive, send: Send) -&gt; None: request = Request(scope, receive=receive, send=send) if is_coroutine: response = await func(request) else: response = await run_in_threadpool(func, request) await response(scope, receive, send) return app 从上边的代码中可以看到，FastAPI中的Route.app实际上上是一个闭包函数。在get_request_handler()中定义的一个异步闭包函数，并将该函数传递给request_response()。request_response()函数调用闭包函数app拿到其返回值Response。并调用Response()(scope, receive, send)实现返回请求。 下面是Response.__call__()的代码，可以看到其中异步调用的send函数，用于返回这次请求的响应。 12345678910111213class Response: async def __call__(self, scope: Scope, receive: Receive, send: Send) -&gt; None: await send( &#123; &quot;type&quot;: &quot;http.response.start&quot;, &quot;status&quot;: self.status_code, &quot;headers&quot;: self.raw_headers, &#125; ) await send(&#123;&quot;type&quot;: &quot;http.response.body&quot;, &quot;body&quot;: self.body&#125;) if self.background is not None: await self.background() 综上，FastAPI从接到请求到返回响应的完整逻辑如下： 根据请求的路径寻找匹配的路由 调用路由的endpoint（即我们自己定义的函数），拿到函数返回值raw_content 根据raw_content生成Response对象 调用response(scope, receive, send)返回响应 3. FastAPI如何处理同步、异步请求在浏览上边的代码时这个问题其实已经解决了，关健就在run_endpoint_function函数中。 async def run_endpoint_function(dependant): ... if is_coroutine: return await dependant.call(**values) else: return await run_in_threadpool(dependant.call, **values) 所以结论就是如果endpoint是一个异步函数，FastAPI会直接调用，而如果是同步函数，会将函数放入线程池中异步调用。 总结从开发者定义一个endpoint到uvicorn服务启动，再到接受请求，返回响应。中间的流程如下。 uvicorn启动一个异步服务器，监听指定端口 接收到请求后，uvicorn解析请求头、路径等参数，保存到scope中 通过ASGI协议，调用app，将scope数据传递给app app遍历所有self.routes，并找到match的路由 Route对象调用开发者挂载的endpoint函数，得到返回值 Route构造Response对象，将endpoint返回值发送回客户端","categories":[{"name":"Learning","slug":"Learning","permalink":"https://dragon-gcs.github.io/categories/Learning/"}],"tags":[{"name":"源码解读","slug":"源码解读","permalink":"https://dragon-gcs.github.io/tags/%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/"},{"name":"FastAPI","slug":"FastAPI","permalink":"https://dragon-gcs.github.io/tags/FastAPI/"}]},{"title":"ubuntu(wsl2)下编译Python3.10","slug":"ubuntu-wsl2-下编译Python3-10","date":"2023-04-09T15:40:04.000Z","updated":"2023-04-09T15:40:04.000Z","comments":true,"path":"2023/04-09-ubuntu-wsl2-下编译Python3-10.html","permalink":"https://dragon-gcs.github.io/2023/04-09-ubuntu-wsl2-%E4%B8%8B%E7%BC%96%E8%AF%91Python3-10","excerpt":"","text":"因为torch2.0的model.compile暂时只支持Linux系统，所以在windows上用wsl2装一个torch，顺便编译一下python3.10 1. 下载源码wget https://www.python.org/ftp/python/3.10.11/Python-3.10.11.tgztar -zxf Python-3.10.11.tgzcd Python-3.10.11 2. 安装依赖 编译源码需要gcc和make，如果已经有了可以跳过安装这两个 sudo apt install gcc make 安装依赖 有了gcc和make之后理论上就可以编译源码了，但是由于依赖的问题，会导致一些模块无法编译，所以需要根据需要安装一些依赖 sudo apt install libbz2-dev libncurses5-dev libncursesw5-dev libgdbm-dev uuid-dev libffi-dev liblzma-dev libsqlite3-dev libssl-dev zlib*-dev libreadline-dev build-essential：用于编译_ctypes模块libbz2-dev：用于编译_bz2模块libncurses5-dev：用于编译_curses模块libncursesw5-dev：用于编译_curses模块libgdbm-dev：用于编译_gdbm模块uuid-dev：用于编译_uuid模块libffi-dev：用于编译_ctypes模块liblzma-dev：用于编译_lzma模块libsqlite3-dev：用于编译_sqlite3模块libssl-dev：用于编译_ssl模块zlib*-dev：用于编译zlib模块libreadline-dev：用于编译readline模块(上边这些都是copilot自动补全的，模块对应的不知道对不对，但是这些依赖没有问题) 3. 编译安装完之后编译，可能只有小部分模块还有问题，但是不影响使用(我这里是_dbm和_tkinter没有编译) ./configure --enable-optimizations --prefix=&lt;/Your/Path&gt;make -j8sudo make install configure的时候可以加上--enable-optimizations，这样编译出来的python会有一些优化，但是编译时间会变长, --prefix指定安装路径make的时候加上-j8，表示开启8个线程编译，加快编译速度 安装完后之后可能还需要做一些软连接的操作，我这里安装目录是/usr，所以不需要这些了直接运行python3 -V就可以看到版本了 4. cuda-toolkit安装因为宿主机上已经有了nvidia的驱动，所以wsl2上不需要再装驱动了，可以用nvidia-smi查看显卡信息。cuda-toolkit是另外的的东西，在这里选好系统后，安装类型选**deb(netword)**，然后复制命令运行就好 具体细节可以看这篇文章 wget https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-keyring_1.0-1_all.debsudo dpkg -i cuda-keyring_1.0-1_all.debsudo apt-get updatesudo apt-get -y install cuda","categories":[{"name":"Learning","slug":"Learning","permalink":"https://dragon-gcs.github.io/categories/Learning/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://dragon-gcs.github.io/tags/Linux/"}]},{"title":"康威生命游戏","slug":"康威生命游戏","date":"2022-07-14T07:31:57.000Z","updated":"2022-07-14T07:31:57.000Z","comments":true,"path":"2022/07-14-康威生命游戏.html","permalink":"https://dragon-gcs.github.io/2022/07-14-%E5%BA%B7%E5%A8%81%E7%94%9F%E5%91%BD%E6%B8%B8%E6%88%8F","excerpt":"","text":"最近奶头乐刷到了康威的生命游戏，感觉挺有意思，实现起来也不难，正好可以熟悉熟悉Js。 康威生命游戏: 剑桥大学John Horton Conway设计的计算机程序。规则如下: 繁殖：当前细胞周围刚好存在3个活细胞，下一次迭代为活细胞 死亡：当前细胞周围存在0&#x2F;1个活细胞，下一次迭代为死细胞 稳定：当前细胞周围存在2&#x2F;3个活细胞，下一次迭代状态不变 拥挤：当前细胞周围活细胞大于3个时，下一次迭代为死细胞 下边是用js实现的生命游戏，功能如下： 黑色表示活细胞，白色表示死细胞 地图尺寸1~100 初始活细胞占比 0~1 点击切换指定位置细胞的状态 GameOfLife Live Rate: Map Size: Js代码在 这里Css代码在 这里","categories":[{"name":"FunnyCoding","slug":"FunnyCoding","permalink":"https://dragon-gcs.github.io/categories/FunnyCoding/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://dragon-gcs.github.io/tags/JavaScript/"}]},{"title":"使用C语言为python添加简单的扩展","slug":"使用C语言为python添加简单的扩展","date":"2022-01-24T15:15:51.000Z","updated":"2022-01-24T15:15:51.000Z","comments":true,"path":"2022/01-24-使用C语言为python添加简单的扩展.html","permalink":"https://dragon-gcs.github.io/2022/01-24-%E4%BD%BF%E7%94%A8C%E8%AF%AD%E8%A8%80%E4%B8%BApython%E6%B7%BB%E5%8A%A0%E7%AE%80%E5%8D%95%E7%9A%84%E6%89%A9%E5%B1%95","excerpt":"","text":"环境要求：C&#x2F;C++编译器，gcc或者MSVC均可 参考自官方文档 使用python-api编写c语言代码首先写一个简单的参数传递函数args_show() 123456789101112131415161718192021222324252627#include &lt;Python.h&gt; // 必须引入Pyhton头文件才可以使用python-api#include &lt;stdio.h&gt;static PyObject* // PyObject对应python万物皆对象args_show(PyObject *self, PyObject *args, PyObject *kwargs)&#123; char* a; char* b; char *foo = &quot;default foo&quot;; char *bar = &quot;default bar&quot;; char *baz = &quot;default baz&quot;; // 关键字列表，对应def args_show(a, b, foo, bar, baz) static char* kwlist[] = &#123;&quot;a&quot;, &quot;b&quot;, &quot;foo&quot;, &quot;bar&quot;, &quot;baz&quot;, NULL&#125;; // 解析关键字参数，| 后为可选参数，解析失败返回NULL if (!PyArg_ParseTupleAndKeywords(args, kwargs, &quot;ss|sss&quot;, kwlist, &amp;a, &amp;b, &amp;foo, &amp;bar, &amp;baz)) &#123; Py_RETURN_NONE; &#125; printf(&quot;a is %s\\n&quot;, a); printf(&quot;b is %s\\n&quot;, b); printf(&quot;foo is %s\\n&quot;, foo); printf(&quot;bar is %s\\n&quot;, bar); printf(&quot;baz is %s\\n&quot;, baz); Py_RETURN_NONE;&#125; 使用Python-api对函数进行封装以及注册 12345678910111213141516171819202122232425262728293031// 将c函数注册为python函数// PyMethodDef为一个列表， 每个元素中包含四个字段：// 注册的python的函数名，对应的c函数，参数接受方法，函数文档static PyMethodDef KeywodsMethod[] = &#123; &#123;&quot;args_show&quot;, (PyCFunction)(void(*)(void))args_show, // METH_VARARGS|METH_KEYWORDS 表示接收位置参数和关键字参数 METH_VARARGS|METH_KEYWORDS, &quot;pratice kwargs&quot;&#125;, // 最后一项为固定值 &#123;NULL, NULL, 0, NULL&#125;&#125;;// 将函数列表注册到python模块static struct PyModuleDef testmodule = &#123; PyModuleDef_HEAD_INIT, &quot;test&quot;, // 模块名__name__， 与import xxx无关 &quot;some docs&quot;, // 模块文档 -1, KeywodsMethod, // 模块中的方法列表&#125;;// 注册模块，使用PyInit_xxx进行初始化，xxx为导入时的模块名PyMODINIT_FUNCPyInit_test(void)&#123; PyObject *m; m = PyModule_Create(&amp;testmodule); if (m == NULL) return NULL; return m;&#125; 使用setup.py对模块进行编译from setuptools import Extension, setupmodule = Extension( &quot;test&quot;, # 模块名，即import test，必须与c文件中PyInit_xxx一致 sources=[&quot;./test.c&quot;] # 模块对应的源文件（们）)setup( ext_modules=[module]) 之后使用python setup.py build_ext --inplace对源文件进行编译。编译后会在当前目录看到一个test.cpxx-xxx_xxx.pyd文件（xxx为编译平台信息）。因为使用了--inplace，如果模块名为xxx.test，编译后的文件会在xxx模块目录下生成。 测试相同目录下新建一个测试文件导入方法进行测试 1234567891011121314from test import args_showargs_show(&quot;1&quot;, &quot;2&quot;)# a is 1# b is 2# foo is default foo# bar is default bar# baz is default bazargs_show(&quot;1&quot;, &quot;2&quot;, &quot;foo&quot;, &quot;bar&quot;)# a is 1# b is 2# foo is foo# bar is bar# baz is default baz 由于自己编写的C拓展模块没有对应的类型注解，可以自己在pyd同目录下编写一个同名的pyi文件用于类型注解 # filename test.pyidef args_show(a: str, b: str, foo: str = &quot;default foo&quot;, bar: str = &quot;default bar&quot;, baz: str = &quot;default baz&quot;) -&gt; None : ...","categories":[{"name":"Learning","slug":"Learning","permalink":"https://dragon-gcs.github.io/categories/Learning/"}],"tags":[{"name":"extension","slug":"extension","permalink":"https://dragon-gcs.github.io/tags/extension/"},{"name":"Python","slug":"Python","permalink":"https://dragon-gcs.github.io/tags/Python/"}]},{"title":"简单的KNN算法实现","slug":"简单的KNN算法实现","date":"2021-12-19T14:07:57.000Z","updated":"2021-12-19T14:07:57.000Z","comments":true,"path":"2021/12-19-简单的KNN算法实现.html","permalink":"https://dragon-gcs.github.io/2021/12-19-%E7%AE%80%E5%8D%95%E7%9A%84KNN%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0","excerpt":"","text":"本文主要用于记录KNN算法实现过程，大部分均为代码 import tqdmimport numpy as npimport pandas as pdimport matplotlib.pyplot as plt 数据集下载与读取mnist数据集地址为 http://yann.lecun.com/exdb/mnist/ 下载完成后解压得到四个二进制文件，需要进行预处理后再进行预测 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950def readLabel(label_dir: str): # 读取标签数据 with open(label_dir, &#x27;rb&#x27;) as f: return np.fromfile(f,offset = 8, dtype=&quot;int8&quot;)def readImages(image_dir: str): # 读取图片数据 with open(image_dir, &#x27;rb&#x27;) as f: magic_num = int.from_bytes(f.read(4), byteorder=&quot;big&quot;) num = int.from_bytes(f.read(4), byteorder=&quot;big&quot;) rows = int.from_bytes(f.read(4), byteorder=&quot;big&quot;) columns = int.from_bytes(f.read(4), byteorder=&quot;big&quot;) return np.fromfile(f, dtype=&quot;uint8&quot;).reshape([num, rows, columns])def make_df(images: np.ndarray, labels: np.ndarray, norm = True) -&gt;pd.DataFrame: &quot;&quot;&quot; 将图片的二维矩阵展平，保存至DataFrame中 &quot;&quot;&quot; assert images.shape[0] == labels.shape[0] images = images.reshape([images.shape[0], -1]) if norm: x_mean = images.mean(axis = 1).reshape(-1, 1) x_std = images.std(axis = 1).reshape(-1, 1) images = (images - x_mean) / x_std df = pd.DataFrame(images) df[&quot;label&quot;] = labels return dfdef dataSplit(df: pd.DataFrame, frac:float = 0.9) -&gt; Tuple[pd.DataFrame, pd.DataFrame]: &quot;&quot;&quot; 划分训练集和验证集 &quot;&quot;&quot; train = df.sample(frac=frac) return train, df.drop(train.index.tolist(), axis=0)train_labels = readLabel(&quot;./Datasets/mnist/train-labels.idx1-ubyte&quot;)test_labels = readLabel(&quot;./Datasets/mnist/t10k-labels.idx1-ubyte&quot;)train_images = readImages(&quot;./Datasets/mnist/train-images.idx3-ubyte&quot;)test_images = readImages(&quot;./Datasets/mnist/t10k-images.idx3-ubyte&quot;)train_df = make_df(train_images, train_labels)# 使用dataSplite(df)划分验证集和训练集# train_df, dev_df = dataSplit(train_df)test_df = make_df(test_images, test_labels) 查看部分图片num = 25images: pd.DataFrame = pd.concat([train_df, test_df], axis=0).sample(n = num)plt.figure(figsize=(10,10), facecolor=&quot;#FFFFFF&quot;)for i in range(25): plt.subplot(5,5,i + 1) img = images.iloc[i, :-1].to_numpy().reshape([28,28]) plt.imshow(img, cmap=&quot;gray&quot;) plt.xticks([]) plt.yticks([]) plt.xlabel(str(images.iloc[i, -1])) PCA降维测试特征值均为复数，因此无法使用PCA进行聚类分析 eigen_w, eigen_v = np.linalg.eig(np.cov(test_df.iloc[:, :-1].T))order = np.argsort(eigen_w)[::-1]order_w = eigen_w[order]order_v = eigen_v[:, order]print(&quot;特征值 1：&quot;, order_w[0]) X = test_df.iloc[:, :-1].dot(order_v[:, :2])plt.scatter(X.iloc[:, 0], X.iloc[:, 1], s = 5, c = test_df.iloc[:, -1].tolist(), cmap=&quot;coolwarm&quot;)plt.colorbar()plt.show() KNN聚类算法1234567891011121314151617181920212223242526272829303132333435def KNN(data: np.ndarray, train_data: np.ndarray, train_label: np.ndarray, k: int, mode: str = &quot;E&quot;, batch = 512, train_batch = 512) -&gt; np.ndarray: assert len(data.shape) == 2 # 4batch -&gt; 4 # 3batch + 1 -&gt; 4 # 3batch -&gt; 3 batch_num = (data.shape[0] - 1) // batch + 1 train_batch_num = (train_data.shape[0] - 1) // train_batch + 1 data = data[:, np.newaxis, :] train_data = train_data[np.newaxis, :, :] # 定义距离公式 if mode == &quot;E&quot;: distance = lambda x, train_x: np.sqrt(np.sum((np.square(x - train_x)), axis = -1)) elif mode == &quot;M&quot;: distance = lambda x, train_x: np.sum(np.abs(x - train_x), axis = -1) else: distance = lambda x, train_x: x # outputs保存每个batch输出的结果[(batch, k)] outputs = [] for i in tqdm.tqdm(range(batch_num)): # 保存各train_batch输出的距离 distances = [] for j in range(train_batch_num): distances.append(distance( data[i * batch: (i + 1) * batch, :, :], train_data[:, j * train_batch: (j + 1) * train_batch, :])) order = np.argsort(np.concatenate(distances, axis = -1), axis = -1)[:, :k] outputs.append(train_label[order]) # 将输出结果拼接为矩阵，（data.shape[0], k) result = np.concatenate(outputs, axis = 0) return np.array([np.argmax(np.bincount(x)) for x in result]) test_num = 200train_data = train_df.iloc[:, :-1].to_numpy()train_label = train_df.iloc[:, -1].to_numpy()data = test_df.sample(test_num)label = data[&quot;label&quot;].to_numpy()data = data[list(range(28*28))].to_numpy()%time pred = np.sum(label == KNN(data, train_data, train_label, k = 5, batch=16))print(&quot;&#123;:.2%&#125;&quot;.format(pred / test_num)) 100%|██████████| 13/13 [00:44&lt;00:00, 3.39s/it] Wall time: 44.1 s 97.00% KNN分类的大致思路就是如此了，自己写的算法在速度上还是有很大的提升空间的，如果要测试完全部10000个样本大概耗时为40min。","categories":[{"name":"Learning","slug":"Learning","permalink":"https://dragon-gcs.github.io/categories/Learning/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://dragon-gcs.github.io/tags/Python/"},{"name":"ML","slug":"ML","permalink":"https://dragon-gcs.github.io/tags/ML/"},{"name":"KNN","slug":"KNN","permalink":"https://dragon-gcs.github.io/tags/KNN/"}]},{"title":"科研工具—文献下载器","slug":"科研工具—文献下载器","date":"2021-11-15T14:33:56.000Z","updated":"2021-11-15T14:33:56.000Z","comments":true,"path":"2021/11-15-科研工具—文献下载器.html","permalink":"https://dragon-gcs.github.io/2021/11-15-%E7%A7%91%E7%A0%94%E5%B7%A5%E5%85%B7%E2%80%94%E6%96%87%E7%8C%AE%E4%B8%8B%E8%BD%BD%E5%99%A8","excerpt":"","text":"GetPaper v2.0基于Sci-Hub的文献下载器，输入关键词后即可在指定数据库中爬取所需文献。 使用ttk.bootstrap重新设计GUI，增加作者、期刊、日期、排序方式选项 使用基于协程的爬虫引擎提高文章爬取速度，同时使用多线程避免GUI线程阻塞问题 增加爬虫引擎接口，可添加其他数据库爬虫。目前已有ACS和PubMed爬虫引擎。 增加翻译功能接口，可添加其他的翻译源，目前使用的是百度翻译Api。 通过Sci-Hub下载指定文献或所有爬取结果的pdf 运行方法项目已打包为exe文件，下载后可直接使用。 运行环境：python3.8+ 克隆本项目后cd至项目目录 使用pip install -r requirements.txt python main.pyw 运行项目 如需打包，运行pyinstaller main.spec，main.spec已配置好相关静态文件。 翻译功能需要自行注册百度翻译Api后将个人appid与key添加到api_info.json中。exe可直接使用翻译。 使用方法 选择需要查询的数据库 输入查询关键词（必选）以及其他搜索条件（PubMed搜索需要同时输入开始时间和截至时间后，搜索时间才会生效） 点击关键词搜索爬取文献数量信息后，输入需要获取的文献数量，点击获取详情开始爬取文献标题、作者、期刊等信息。不建议在不清楚文献搜索结果总数时直接点击获取详情，如果获取数量大于搜索结果数量会等待至Timeout后结束任务 双击搜索结果打开详情页，点击翻译按钮对文献标题和摘要内容进行翻译，点击下载按钮将从Sci-Hub下载本文献的pdf 主界面的全部下载用于从Sci-Hub下载搜索结果中的所有文献的pdf文件，如下载失败会生成对应的txt文件。为避免对其服务器造成过大压力，已限制下载频率。 主界面的导出数据用于将搜索结果导出为csv文件，可使用excel另存为xls或xlsx 项目结构├─getpaper│ ├─GUI # GUi模块│ ├─spiders # 爬虫模块│ ├─translator # 翻译模块│ ├─config.py # 相关配置文件│ ├─download.py # Sci-Hub下载模块│ └─utils.py # 工具模块├─hook # 用于pyinstaller打包，用于导入项目中动态导入的模块└─main.pyw # 入口 爬虫引擎接口 在getpaper/spiders内添加name.py文件后能够被自动识别并在GUI中显示，如需打包为exe文件，则必须在getpaper/config.py中if hasattr(sys, &quot;frozen&quot;)时spider_list中添加对应的&lt;name&gt;，否则打包后无法识别动态导入的模块。 类名必须为Spider且继承getpapaer._spiders中的_Spider基类，用于检测爬虫是否实现了以下方法： 初始化爬虫时调用的方法，用于接受GUI传入的搜索相关条目，进行解析后用于搜索，其中sorting为搜索结果，包括”相关性”， “日期”， “日期逆序”。 123456789101112131415161718192021222324class _Spider(ABC): def __init__(self, keyword: str = &quot;&quot;, start_year: str = &quot;&quot;, end_year: str = &quot;&quot;, author: str = &quot;&quot;, journal: str = &quot;&quot;, sorting: str = &quot;&quot;) -&gt; None: &quot;&quot;&quot; Base spider Args: keyword: keyword, split by space start_year: default to 1900 end_year: default to next year author: filter by author, default to None journal: filter by published journal, default to None sorting: sorting result by details or match &quot;&quot;&quot; self.data = self.parseData(keyword, start_year, end_year, author, journal, sorting) def parseData(self, keyword: str, start_year: str = &quot;&quot;, end_year: str = &quot;&quot;, author: str = &quot;&quot;, journal: str = &quot;&quot;, sorting: str = &quot;&quot;) -&gt; Dict[str, Any]: 根据搜索信息对数据库进行查找，并返回找到的文献数量提示信息，返回的字符串用于在GUI显示。 def getTotalPaperNum(self) -&gt; str: &quot;&quot;&quot; Get the total number of result Returns: num: number of search result &quot;&quot;&quot; pass 获取num篇文献的标题、作者、发表时间、发表期刊、摘要、doi号、网址，并将结果保存至queue中，该队列还用于监控当前的下载进度。 def getAllPapers(self, queue: PriorityQueue, num: int) -&gt; None: &quot;&quot;&quot; Get all papers detail Params: queue: a process queue for storing result and feedbacking progess, details format is [index, (title, authors, date, publication, abstract, doi, web)] num: number of papers to get &quot;&quot;&quot; pass 数据保存顺序参考如下，不得更改顺序。其中index为文献的序号，用于按序输出搜索结果。 queue.put(index, (title, authors, date, publication, abstract, doi, web)) 翻译引擎接口 在getpaper/translator内添加name.py文件后能够被自动识别并在GUI中显示，如需打包为exe文件，则必须在getpaper/config.py中if hasattr(sys, &quot;frozen&quot;)时translator_list中添加对应的&lt;name&gt;，否则打包后无法识别动态导入的模块。 类名必须为Translator，用于动态导入该模块 api相关数据保存在getpaper/translator/_api_info.json中，推荐使用以下方法读取该json文件，该方法能够在打包后正常读取文件。 f = importlib.resources.open_text(&#x27;getpaper.translator&#x27;, &#x27;_api_info.json&#x27;)info = json.load(f) 实现translate(self, detail: str) -&gt; str方法，文章的title和abstract会分别调用此方法进行翻译，返回的字符串会通过str()转换后显示到文本框内。 其他 使用协程函数：使用getpaper.utils中的@AsyncFunc对主协程函数进行装饰，才可以被正常调用。 异常处理：捕获异常后使用getpaper.utils中的TipException(tip)，通过唤起该异常可以在GUI中显示对应的tip信息，不超过16个字符（8个汉字）。如果异常导致爬取任务中断，建议使用数据将queue填满或修改queue.max_size，否则在队列为full之前，GUI中的监控进度条与后台下载任务将持续运行至默认TIMEOUT。TIMEOUT可在getpaper/config.py中进行修改 GetPaper 1.0 根据输入的关键词，从选择的数据库中爬取文献的标题、作者、期刊、日期、摘要、doi和网址等信息。 保存按钮可以将爬取到的信息保存至本地。 下载按钮是根据爬取到的doi信息从sci-hub下载文献，但有时会出现http.client.IncompleteRead导致文献无法下载，与个人网络情况有关。 后续改进计划 优化爬取结果的表现方法 可从结果中选择需要下载的文献 尝试增加其他数据库 使用多线程提高文献信息获取速度 v1.0下载地址 pyinstaller打包后的exe文件大小为27M，保存在百度网盘提取码：0u7n。","categories":[{"name":"Project","slug":"Project","permalink":"https://dragon-gcs.github.io/categories/Project/"}],"tags":[{"name":"Async","slug":"Async","permalink":"https://dragon-gcs.github.io/tags/Async/"},{"name":"GUI","slug":"GUI","permalink":"https://dragon-gcs.github.io/tags/GUI/"},{"name":"Spider","slug":"Spider","permalink":"https://dragon-gcs.github.io/tags/Spider/"}]},{"title":"Tensorflow与CUDA的安装","slug":"Tensorflow与CUDA的安装","date":"2021-10-29T12:47:28.000Z","updated":"2021-10-29T12:47:28.000Z","comments":true,"path":"2021/10-29-Tensorflow与CUDA的安装.html","permalink":"https://dragon-gcs.github.io/2021/10-29-Tensorflow%E4%B8%8ECUDA%E7%9A%84%E5%AE%89%E8%A3%85","excerpt":"","text":"在安装CUDA时查找了不少资料，要么太旧要么太乱写的不知道他在干什么，于是自己整理了一下CUDA的安装过程，以此记录。本人使用的显卡为GTX 1660 Super，系统为Win10，Tensorflow版本为2.6.0，以下步骤为本人卸载了Tensorflow和CUDA后从头开始的安装步骤，亲测可行。 Tensorflow的安装Tensorflow在1.15版本后已经将CPU版本和GPU版本进行了合并，可以很简单的通过pip来进行安装 pip install tensorflow 安装完成后会自动检测系统中是否已经安装了CUDA套件，在检测到CUDA时，所有计算会优先使用GPU进行计算。 如果需要使用pyTorch，则后续选择CUDA版本时应该参照PyTorch官网如果需要同时使用Tensorflow和pyTorch，则后续选择CUDA版本的时候应尽量选择一个能够同时用于pyTorch和Tensorflow的版本。所有版本的pyTorch支持的CUDA可以在https://pytorch.org/get-started/previous-versions/查询。需要指出的是pyTorch所用的CUDA需要严格按照官网给出的CUDA版本号进行安装，而Tensorflow给出个CUDA版本号仅为官方验证可用的版本号，所以其他版本的CUDA也可能可以用于Tensorflow，但需要自行安装尝试。 CUDA与cuDNN的安装CUDA为Nvida的开发工具，也叫CUDA Toolkit，cuDNN为Tensorflow运行时需要的依赖文件。网上不少文章安装前都要检查一下本机的英伟达驱动版本信息，本人在测试时发现不需要进行检查，只要确认自己的显卡支持CUDA并安装正确版本的CUDA和cuDNN即可。下面的步骤为如何确认自己的显卡是否支持CUDA以及如何确定自己需要的CUDA和cuDNN版本号 确认显卡是否支持CUDA安装前需要确认自己的显卡是否支持CUDA，Nvida的显卡可以在官网查看对应的型号是否支持CUDA，未在列表的显卡也可进行安装尝试，如本人显卡为GTX 1660 super，安装CUDA后也可正常使用Tensorflow。 查看地址：https://developer.nvidia.com/cuda-gpus Tensorflow官网上并未说明对AMD显卡的支持。 确认显卡驱动版本在桌面右键选择NVDIA控制面板，查看自己当前的版本信息。之后根据官网文档确定自己的显卡能够支持的CUDA版本。 比如我的驱动版本为471.41，根据文档显示我可以安装CUDA 11.4 Updata2以下的所有版本。 确认所需的CUDA与cuDNN版本（cuDNN版本必须与CUDA版本对应）不同版本的Tensorflow对应的cuDNN与CUDA的版本参见下表，表中对应版本号为官方测试通过的版本号，尽量保持一致。 来源：https://tensorflow.google.cn/install/source_windows 下载CUDA与cuDNN确认自己的显卡支持CUDA后，前往Nvida官网下载自己所需版本的CUDA工具包和cuDNN依赖 CUDA工具包：https://developer.nvidia.com/cuda-toolkit-archive cuDNN依赖：https://developer.nvidia.com/rdp/cudnn-archive（需要注册一个Nvida的账号） 1. CUDA下载 打开官网页面后会看到所有版本的CUDA工具包，我这里选择的是11.2.2 接下来选择对应的系统版本和安装方式，最后点击下载等待下载完成。 2. cuDNN下载 在cuDNN的列表中选择支持11.1CUDA的8.1.1windows版本 安装CUDA1. 安装CUDA 打开下载好的CUDA安装文件，按下边的流程进行安装。 全部设置完成后点击下一步并等待安装完成后即可 2. cuDNN组件安装 cuDNN下载完成后是一个压缩包，打开压缩包并将其内容解压至刚刚安装的CUDA Development文件夹内即可。如果弹出是否合并文件夹提示点击确定即可。 3. 设置环境变量 打开系统的环境变量设置，CUDA安装时应该会在系统变量中自动添加两个CUDA_PATH变量，如果未添加则自己手动进行添加。 系统变量确认正确后双击用户变量中的Path（或者选中后点击编辑），在弹出的变量设置窗口添加两个新的路径，分别是&lt;CUDA_Development_Path&gt;\\bin和&lt;CUDA_Development_Path&gt;\\lib\\x64。&lt;CUDA_Development_Path&gt;替换为刚刚记下的CUDA安装路径。（没有意外的应该与系统变量中的CUDA_PATH一致，所以建议写%CUDA_PATH%\\bin和%CUDA_PATH%\\lib\\x64） 测试GPU是否可用在python中执行下面的命令测试目前GPU是否可用 import tensorflow as tf# 列出所有可用的物理设备tf.config.list_physical_devices() 列表中出现PhysicalDevice(name=&#39;/physical_device:GPU:0&#39;, device_type=&#39;GPU&#39;)说明当前环境下Tensorflow能够使用GPU继续训练。 也可以使用tf.test.is_gpu_available()进行检测，返回True说明GPU可用。 写文不易，求个打赏~~","categories":[{"name":"Learning","slug":"Learning","permalink":"https://dragon-gcs.github.io/categories/Learning/"}],"tags":[{"name":"DeepLearning","slug":"DeepLearning","permalink":"https://dragon-gcs.github.io/tags/DeepLearning/"},{"name":"Tensorflow","slug":"Tensorflow","permalink":"https://dragon-gcs.github.io/tags/Tensorflow/"}]},{"title":"Matplotlib绘制3D折线图","slug":"Matplotlib绘制3D折线图","date":"2021-10-20T12:08:20.000Z","updated":"2021-10-20T12:08:20.000Z","comments":true,"path":"2021/10-20-Matplotlib绘制3D折线图.html","permalink":"https://dragon-gcs.github.io/2021/10-20-Matplotlib%E7%BB%98%E5%88%B63D%E6%8A%98%E7%BA%BF%E5%9B%BE","excerpt":"","text":"绘图相关设置导入相关库 import numpy as npimport pandas as pdimport matplotlib.pyplot as pltfrom matplotlib.collections import PolyCollection # 用于绘制三维图像 首先对绘制的图像进行一下设置，绘制数据如果有变化，在这里更改相应的设置即可 1234567891011121314151617181920212223# 文件名csv_filename = &quot;test.csv&quot;# 字体设置FONTS = &quot;Times New Roman&quot;# 折线图颜色， 每个切面对应一个颜色，如果只有一个值则所有切面均使用同一个颜色COLOR = [&#x27;darkviolet&#x27;, &#x27;purple&#x27;, &#x27;green&#x27;, &#x27;yellow&#x27;, &#x27;red&#x27;]CONFIG = &#123;&quot;alpha&quot;:[0.8], # 折线图透明度 &quot;facecolor&quot;: COLOR, # 折线图颜色 &quot;edgecolors&quot;: COLOR, # 折线图边缘线条颜色 &quot;linewidths&quot;:2.0 # 折线图边缘线条粗细 &#125;# 是否显示网格GRID = False##################### X 轴 #####################X_label = &quot;Raman Shift(cm$^&#123;-1&#125;$)&quot; # X轴标签X_range = range(0, 2001, 500) # X轴坐标范围, range(最小值，最大值(不包含)，间距)##################### Y 轴 #####################Y_label = &quot;Bacterial Concentration(CFU)&quot; # Y轴标签Y_ticklabels = [&quot;100&quot;, &quot;50&quot; ,&quot;10&quot; ,&quot;1&quot;, &quot;0&quot;] # Y刻度标签##################### Z 轴 #####################Z_laebl = &quot;Intensity(a.u.)&quot; # Z轴标签Z_range = (0, 20000) # Z轴范围（最小值， 最大值） 绘制图像新建一个类，读取指定文件并进行绘制。文件中第一列为X轴，其余列分别为不同组的Y值 class WaterFall: def __init__(self, filename:str,) -&gt; None: self.raw_data = pd.read_csv(filename, sep=&quot;\\t&quot;).values self.data_process() # 处理数据 预处理数据，转换为三维折线图所需要的格式 1234567891011121314151617def data_process(self) -&gt; None: # 使用np.pad()对数据的第一行和最后一行填充0 # np.pad(array, [(第1维度填充宽度(行)), (第2维度填充宽度(列))]) data = np.pad(self.raw_data, [(1,1), (0,0)]) # 数据开头添加一行[min(x), 0, 0, ...] data[0, 0] = self.raw_data[0, 0] # 数据结尾添加一行[max(x), 0, 0, ...] data[-1, 0] = self.raw_data[-1, 0] self.data = [] for i in range(1, data.shape[1]): self.data.append(data[:,[0, i]]) # 绘制三维折线图需要的数据格式为 # [[X, Y1], [X, Y2].....] # 其中每组数据的Y开头和结尾都必须是0，否则会画不出图像 # 因为需要提前在数据开头和结尾添加一行数据0，x对应的为X的最小值和最大值 绘制曲线 1234567891011121314151617181920212223242526272829303132def show(self): # 选择绘制模式为3D, 设置图片大小（英寸）和分辨率（dot per inch) canvas = plt.figure(figsize=(12,8), dpi=150).add_subplot(projection=&#x27;3d&#x27;) # 设置X, Y, Z轴的比例 canvas.set_box_aspect(aspect = (1,1.3,0.8)) canvas.add_collection3d(PolyCollection(self.data[::-1], **CONFIG), # 由于数据为逆序，这里将数据倒置 # Z轴（X，Y之外的第三维度，非实际Z轴）为需要绘制折线图的数量 zs = range(len(self.data)), # 设置Z轴显示Y数据 zdir = &#x27;y&#x27;) # 设置字体 plt.rcParams[&quot;font.sans-serif&quot;] = FONTS # 设置坐标轴标题 canvas.set_xlabel(X_label) canvas.set_ylabel(Y_label) canvas.set_zlabel(Z_laebl, labelpad=-15) # 设置坐标轴显示范围 canvas.set_ylim(-0.5, len(self.data) - 0.5) canvas.set_zlim(*Z_range) # 设置坐标轴刻度 canvas.set_xticks(X_range) # 设置Y轴刻度标签 canvas.set_yticklabels([&quot;&quot;, *Y_ticklabels]) # 取消Z轴刻度显示 canvas.set_zticks([]) canvas.grid(GRID) # 设置三个轴平面的背景颜色为灰色，颜色用(R,G,B,Alpha)表示，取值0~1 canvas.w_xaxis.set_pane_color((0,0,0,0.1)) canvas.w_yaxis.set_pane_color((0,0,0,0.1)) canvas.w_zaxis.set_pane_color((0,0,0,0.1)) plt.show() 配置完成后运行绘制即可看到成品 if __name__ == &#x27;__main__&#x27;: wf = WaterFall(csv_filename) wf.show() Matploblib显示所有可用颜色的方法使用官方提供的示例可以可视化看到plt中所有支持的颜色 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768from matplotlib.patches import Rectangleimport matplotlib.pyplot as pltimport matplotlib.colors as mcolorsdef plot_colortable(colors, title, sort_colors=True, emptycols=0): cell_width = 212 cell_height = 22 swatch_width = 48 margin = 12 topmargin = 40 # Sort colors by hue, saturation, value and name. if sort_colors is True: by_hsv = sorted((tuple(mcolors.rgb_to_hsv(mcolors.to_rgb(color))), name) for name, color in colors.items()) names = [name for hsv, name in by_hsv] else: names = list(colors) n = len(names) ncols = 4 - emptycols nrows = n // ncols + int(n % ncols &gt; 0) width = cell_width * 4 + 2 * margin height = cell_height * nrows + margin + topmargin dpi = 72 fig, ax = plt.subplots(figsize=(width / dpi, height / dpi), dpi=dpi) fig.subplots_adjust(margin/width, margin/height, (width-margin)/width, (height-topmargin)/height) ax.set_xlim(0, cell_width * 4) ax.set_ylim(cell_height * (nrows-0.5), -cell_height/2.) ax.yaxis.set_visible(False) ax.xaxis.set_visible(False) ax.set_axis_off() ax.set_title(title, fontsize=24, loc=&quot;left&quot;, pad=10) for i, name in enumerate(names): row = i % nrows col = i // nrows y = row * cell_height swatch_start_x = cell_width * col text_pos_x = cell_width * col + swatch_width + 7 ax.text(text_pos_x, y, name, fontsize=14, horizontalalignment=&#x27;left&#x27;, verticalalignment=&#x27;center&#x27;) ax.add_patch( Rectangle(xy=(swatch_start_x, y-9), width=swatch_width, height=18, facecolor=colors[name], edgecolor=&#x27;0.7&#x27;) ) return figplot_colortable(mcolors.BASE_COLORS, &quot;Base Colors&quot;, sort_colors=False, emptycols=1)plot_colortable(mcolors.CSS4_COLORS, &quot;CSS Colors&quot;)# Optionally plot the XKCD colors (Caution: will produce large figure)#xkcd_fig = plot_colortable(mcolors.XKCD_COLORS, &quot;XKCD Colors&quot;)#xkcd_fig.savefig(&quot;XKCD_Colors.png&quot;)plt.show() 基础颜色 CSS颜色","categories":[{"name":"Learning","slug":"Learning","permalink":"https://dragon-gcs.github.io/categories/Learning/"}],"tags":[{"name":"Matplotlib","slug":"Matplotlib","permalink":"https://dragon-gcs.github.io/tags/Matplotlib/"}]},{"title":"遗传算法的Python实现","slug":"遗传算法的Python实现","date":"2021-10-09T11:49:10.000Z","updated":"2021-10-09T11:49:10.000Z","comments":true,"path":"2021/10-09-遗传算法的Python实现.html","permalink":"https://dragon-gcs.github.io/2021/10-09-%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95%E7%9A%84Python%E5%AE%9E%E7%8E%B0","excerpt":"","text":"遗传算法的原理可以参考此文章 看着图片从杂乱的像素点一点一点逼近目标图片是一个十分有趣的过程。 本次以360的logo作为目标图片 1.设置相关参数SIZE = 64TOTAL_POP = 4MUTATION = 0.4MIN_MUTATION = 0.1 / (SIZE*SIZE)MUTATION_DECAY = 3e-5MAX_FIT = []TOTAL_FIT = []MUTATION_SPAN = SIZE//2 + 1 size：图片缩放后尺寸 TOTAL_POP：种群内的个体数量 MUTATION：初始突变系数 MIN_MUTATION：最低突变系数 MUTATION：突变系数在每次迭代的衰减值 MAX_FIT：保存每次筛选的最佳fitness，此例中fitness取最小值 TOTAL_FIT：每次筛选中的所有个体的fitness的总和 MUTATION_SPAN：基因重组片段的最长范围 2. 实现基因重组123456789101112def recombination(population): # 将按fitness排序的种群顺序打乱 children = population.copy() np.random.shuffle(children) # 两两杂家 for i in range(0, TOTAL_POP, 2): pos = np.random.randint(SIZE*SIZE) # 随机选择重组位点 span = np.random.randint(1,MUTATION_SPAN) # 随机选择重组片段长度 children[i,pos:pos+span], children[i+1, pos:pos+span] = \\ children[i+1, pos:pos+span], children[i,pos:pos+span] # 交换片段 population = np.concatenate([population, children],axis=0) # 重组后的种群与未重组的合并 return population 3.实现点突变def mutation(population): total = population.shape[0] # 种群内个体数目 p = np.array([1-MUTATION, MUTATION]) # 突变率与不突变率 # 生成与种群矩阵形状一致的突变矩阵，其中1和0表示突变和不突变，数目与突变率一致 mask = np.random.choice([0,1], total*SIZE*SIZE, p=p).reshape((total,-1)) # 进行点突变 population = np.square(mask - population) return population 4. 定义筛选过程1234567891011def choice(population, target): total = population.shape[0] target = target.reshape((1,-1)) # 将图片展平便于计算 target = target.repeat(total, axis=0) # 扩充图片维度与个体数一致 # 计算fitness fitness = np.sum(np.square(population - target), axis=1) / (SIZE*SIZE) order = fitness.argsort() # 从小到大排列个体，此处保存的为索引值 MAX_FIT.append(fitness[order[0]]) TOTAL_FIT.append(np.sum(fitness)) # 选择fitness最低的个体进入下一个轮回 return population[order[:TOTAL_POP]] 5. 功能函数123456789101112131415161718192021222324252627282930313233# 绘制结果图def draw(population, target): plt.subplot(4, 1, 1) plt.title(f&quot;Min:&#123;MIN_MUTATION:.1e&#125; Decay:&#123;MUTATION_DECAY:.1e&#125;\\n&quot; f&quot;Pop:&#123;TOTAL_POP&#125; Span:&#123;MUTATION_SPAN-1&#125; Min:&#123;MAX_FIT[-1]:.1e&#125;&quot;) plt.imshow(target) plt.xticks([]) plt.yticks([]) for i in range(4): plt.subplot(4,2,i+3) plt.imshow(population[i].reshape((SIZE,SIZE))) plt.xticks([]) plt.yticks([]) plt.subplot(4,2,7) plt.plot(TOTAL_FIT) plt.legend(&quot;Total&quot;, fontsize=6) plt.subplot(4,2,8) plt.plot(MAX_FIT) plt.legend(&quot;Min&quot;, fontsize=6) plt.tight_layout() plt.show() # 读取图片并进行压缩def readImage(filename) image = cv2.imread(filename) image = cv2.resize(image, (SIZE,SIZE)) image = np.sum(image, axis=-1) image[image&lt;=127*3] = 0 image[image&gt;127*3] = 1 return image 6.开始进行选择123456789101112131415161718import cv2import numpy as npfrom matplotlib import pyplot as plttarget = readImage(&quot;360logo.png&quot;)for i in range(100000): if MUTATION &gt; MIN_MUTATION: MUTATION -= MUTATION_DECAY if i % 500 == 499: print(&quot;Generation: &quot;+str(i+1)) population = recombination(population) population = mutation(population) population = choice(population, target) if i % 20000 == 19999: # 两万轮展示一次当前进度 draw(population, target) 按照上述参数进行筛选完成后，即可得到最佳个体 遗传算法的关键就是计算fitness，只能够对每轮迭代内个体的优劣及逆行评估就能使用遗传算法进行优化，本例中是将个体与简化后的目标图片的像素值做差来进行评估，使用原始三通道图片将其像素值转化为8位二进制（0-255）也可进行计算。","categories":[{"name":"Learning","slug":"Learning","permalink":"https://dragon-gcs.github.io/categories/Learning/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://dragon-gcs.github.io/tags/Python/"},{"name":"GeneticAlgorithm","slug":"GeneticAlgorithm","permalink":"https://dragon-gcs.github.io/tags/GeneticAlgorithm/"},{"name":"ML","slug":"ML","permalink":"https://dragon-gcs.github.io/tags/ML/"}]},{"title":"使用Hexo搭建个人博客","slug":"使用hexo搭建个人博客","date":"2021-10-09T01:56:46.000Z","updated":"2021-10-09T01:56:46.000Z","comments":true,"path":"2021/10-09-使用hexo搭建个人博客.html","permalink":"https://dragon-gcs.github.io/2021/10-09-%E4%BD%BF%E7%94%A8hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2","excerpt":"","text":"记录hexo搭建个人博客的过程，也是个人github.io仓库的使用说明 安装hexohexo是一个静态网页框架，使用hexo搭建好环境后，作者只需要负责写作即可，hexo会自动识别sourece/_post文件夹中的文件并渲染成网页。配合TravisCI即可在每次push后自动更新网站。 安装hexo需要提前安装以下软件： npm git 运行npm install -g hexo 启动新项目 hexo init &lt;folder&gt; # 非全局安装使用npx hexocd &lt;folder&gt;npm install 或者使用克隆的仓库 git clone &lt;repo_url&gt;cd &lt;repo_name&gt;npm install 项目配置项目的所有配置都保存在_config.yml中，配置内容说明见官方文档，本项目修改配置为： language: zh-CNpermalink: :year/:month-:day-:title/ # 自动生成文章url的格式new_post_name: :year/:year-:month-:day-:title.md # 新建文章时的文件名格式titlecase: true # 英文首字母大写theme: pure # 使用pure主题post_asset_folder: true # 新建文章时自动生成assert文件夹，便于markdown引用图片等资源marked: prependRoot: true # 可以使用相对路径直接导入图片[image1](image.jpg) postAsset: true # build时一同打包assert文件 主题设置本项目的使用的主题为Pure，主题配置文件为themes/pure/_config.yml，本项目修改的主要配置为： 修改配置文件中的个人信息以及themes/pure/source/image中的相关图片 暂时关闭侧边栏中的豆瓣图书 复制themes\\pure\\_source文件夹至根目录并重命名为source中，用于启用侧边栏 修改source\\_data\\links.yml中的友链 menu_highlight: true，是当前标签高亮 启用不蒜子记录文章访问次数 注册Valine并启用Valine评论系统，可以通过LeanCloud的应用中的class进行管理 使用TravisCI自动发布文章hexo发布了部署功能，现在修改配置后，直接使用hexo d即可发布 githubAPP中添加TravisCI 在Github网页中设置App的仓库访问权限Setting &gt; Application &gt; TravisCI Configure &gt; Repository access &gt; choose GitPages Repo 登录Travis官网，同步仓库，在设置中添加环境变量GH_TOKEN， value为github生成的token，只需要开通repo权限即可 在项目目录中添加.travis.yml，Traivs会自动监控指定分支的提交，并执行hexo generate，将生成的public文件夹发布到gh-pages分支，内容如下： 123456789101112131415161718sudo: falselanguage: node_jsnode_js: - 16 # use correct versioncache: npmbranches: only: - main # build master branch onlyscript: - hexo generate # generate static filesdeploy: provider: pages skip-cleanup: true github-token: $GH_TOKEN keep-history: true on: branch: main local-dir: public 在github仓库中设置sourcce为gh-pages分支 新文章的提交克隆仓库的主分支到本地或使用git pull更新本地仓库 npm installhexo new filenamegit add .git commit -m &quot;commit&quot;git push 如果文章中需要引用其他静态资源，可以在同一目录内新建一个相同名称的文件夹（不含后缀），可以直接使用相对引用。 例如_post\\2021\\demo.md引用_post\\2021\\demo\\demo.jpg可以直接写为![img](demo.jpg)。","categories":[{"name":"Learning","slug":"Learning","permalink":"https://dragon-gcs.github.io/categories/Learning/"}],"tags":[{"name":"Blog","slug":"Blog","permalink":"https://dragon-gcs.github.io/tags/Blog/"},{"name":"Hexo","slug":"Hexo","permalink":"https://dragon-gcs.github.io/tags/Hexo/"}]}],"categories":[{"name":"技术探索","slug":"技术探索","permalink":"https://dragon-gcs.github.io/categories/%E6%8A%80%E6%9C%AF%E6%8E%A2%E7%B4%A2/"},{"name":"NAS","slug":"NAS","permalink":"https://dragon-gcs.github.io/categories/NAS/"},{"name":"Website","slug":"Website","permalink":"https://dragon-gcs.github.io/categories/Website/"},{"name":"Learning","slug":"Learning","permalink":"https://dragon-gcs.github.io/categories/Learning/"},{"name":"FunnyCoding","slug":"FunnyCoding","permalink":"https://dragon-gcs.github.io/categories/FunnyCoding/"},{"name":"Project","slug":"Project","permalink":"https://dragon-gcs.github.io/categories/Project/"}],"tags":[{"name":"AI","slug":"AI","permalink":"https://dragon-gcs.github.io/tags/AI/"},{"name":"HomeAssistant","slug":"HomeAssistant","permalink":"https://dragon-gcs.github.io/tags/HomeAssistant/"},{"name":"dns","slug":"dns","permalink":"https://dragon-gcs.github.io/tags/dns/"},{"name":"cloudflare","slug":"cloudflare","permalink":"https://dragon-gcs.github.io/tags/cloudflare/"},{"name":"domain","slug":"domain","permalink":"https://dragon-gcs.github.io/tags/domain/"},{"name":"Rust","slug":"Rust","permalink":"https://dragon-gcs.github.io/tags/Rust/"},{"name":"工具分享","slug":"工具分享","permalink":"https://dragon-gcs.github.io/tags/%E5%B7%A5%E5%85%B7%E5%88%86%E4%BA%AB/"},{"name":"源码解读","slug":"源码解读","permalink":"https://dragon-gcs.github.io/tags/%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/"},{"name":"FastAPI","slug":"FastAPI","permalink":"https://dragon-gcs.github.io/tags/FastAPI/"},{"name":"Linux","slug":"Linux","permalink":"https://dragon-gcs.github.io/tags/Linux/"},{"name":"JavaScript","slug":"JavaScript","permalink":"https://dragon-gcs.github.io/tags/JavaScript/"},{"name":"extension","slug":"extension","permalink":"https://dragon-gcs.github.io/tags/extension/"},{"name":"Python","slug":"Python","permalink":"https://dragon-gcs.github.io/tags/Python/"},{"name":"ML","slug":"ML","permalink":"https://dragon-gcs.github.io/tags/ML/"},{"name":"KNN","slug":"KNN","permalink":"https://dragon-gcs.github.io/tags/KNN/"},{"name":"Async","slug":"Async","permalink":"https://dragon-gcs.github.io/tags/Async/"},{"name":"GUI","slug":"GUI","permalink":"https://dragon-gcs.github.io/tags/GUI/"},{"name":"Spider","slug":"Spider","permalink":"https://dragon-gcs.github.io/tags/Spider/"},{"name":"DeepLearning","slug":"DeepLearning","permalink":"https://dragon-gcs.github.io/tags/DeepLearning/"},{"name":"Tensorflow","slug":"Tensorflow","permalink":"https://dragon-gcs.github.io/tags/Tensorflow/"},{"name":"Matplotlib","slug":"Matplotlib","permalink":"https://dragon-gcs.github.io/tags/Matplotlib/"},{"name":"GeneticAlgorithm","slug":"GeneticAlgorithm","permalink":"https://dragon-gcs.github.io/tags/GeneticAlgorithm/"},{"name":"Blog","slug":"Blog","permalink":"https://dragon-gcs.github.io/tags/Blog/"},{"name":"Hexo","slug":"Hexo","permalink":"https://dragon-gcs.github.io/tags/Hexo/"}]}